I am an electrical engineer specializing in RF transmission and radio. The problem with bass tones may have been in the speakers of the receiving radio unit; it was certainly not in the transmission.
Human hearing has an audio frequency range of 20 Hz (very low) to 20,000 Hz (20 kHz, very high). Most people over 40 have lost the upper end of this range. Once you're not a teenager any more, your hearing starts to attenuate above about 10kHz. Teenagers used to take advantage of this change to use their cell phones in class, setting their rinones to a very high "mosquito tone" in the 15 to 20kHz range. They could hear it, the older teacher couldn't.
All of this means, in short, that transmitting the lower bass band of human speech is not so hard. Transmitting the upper band is more difficult, but usually unnecessary. The real challange with bass is in reproduction. Lower frequency sounds needs a larger speaker - lower frequency means longer wavelenh, and longer wavelenh means physically larger structures. The wavelenh of a sound wave is equal to the speed of sound divided by the frequency - so a 20 Hz sound needs a 16m speaker for full-wave reproduction, but a 3.3kHz sound needs a 10cm speaker. This relates to the huge speakers you see as bass drivers at a concert. Fortunately there are some tricks we can play to get good low tones out of smaller speakers, or your home stereo would be enormous. It also explains why you can always hear your neighbor's bass line just fine through the wall. A 4-inch thick wall can attenuate most of a short wave, but a big long bass wavefront does not even notice the obstacle.
Another place you run into technical restriction of voice band transmission is on the telephone. Plain old telephone service, called POTS for short, encodes 300 - 3300 Hz and cuts off the rest. This is why hold music often sounds so awful - it's missing both the bass, and the high end. There has traditionally been an industry producing special music used specifically for telephone transmission as hold music etc - that's why a large company may have hold music that doesn't suck so bad, but a small company, trying to use some MP3 they loaded onto their call manager as hold music, sounds like tin-plated death. Your cell phone, encoding voice as a digital data stream instead of old-fashioned analog, can capture and transmit much more data - my Samsung Galaxy Note 8 has a little "HD" phone symbol it uses to show me that it's sending higher fidelity audio, something like 50 Hz - 15 kHz, to a similarly-equipped digital handset on the other end.
This honestly does not matter much, because almost all vocal information in human speech encodes entirely in the lower frequency bands. Some quick internet research confirms that the primary frequency data in human speech is in the 50 to 500 Hz range. The range we are taught in school is up to 5kHz, to catch and encode harmonics generated in this range.
Amplitude Modulated (AM) radio transmission was discovered/invented in the late 1800s, and was in wide commercial use by around 1920. It's still in use today, using carrier frequencies of 550 to 1720 kHz. Commercial AM encodes audio frequencies up to 5kHz, which is fine for speech, but not so good for music. Music, especially classical, uses the whole frequency range of human hearing, encoding information and harmonics up to 20kHz and beyond. That's why almost all AM radio is speech-based talk radio, and music on AM stations tends to sound flat - the lively upper frequency band has been entirely removed.
AM Radio was first onto the scene because it's technically easy to do. Building an AM radio receiver is a standard first electronics project for kids as young as 8 years old. A transmitter needs more power, but is also fairly simple. Frequency modulation, FM, is technically more difficult, but like many things in engineering, has some payback for the difficulty. Using FM, you can smash more information into the same amount of RF spectrum. Commercial FM encodes audio up to 15 kHz, which makes it much more suited to music. That's why so much music is on the FM dial of your radio.
There may have been, almost certainly is, some socio-culteral reason for the use of a specific accent on a nationwide broadcast system. There is not any technical reason for it.
Your description of AM broadcast is not quite correct. Up until 1989 AM broadcast had an audio bandwidth of 15KHz and a channel bandwidth of 30KHz. That's the same audio bandwidth as available to mono FM broadcast. Music played back just fine on AM.
The reason music stations moved to FM broadcast is manifold. Receivers got cheaper and more widespread. While FM broadcast didn't offer more audio bandwidth it was naturally less susceptible to noise so it sounded better. It also offered stereo audio which more music was taking advantage of in the late 60s and 70s with the availability of stereo records.
In 1989 the NRSC reduced the audio bandwidth of AM broadcast to 10KHz to allow for a 20KHz channel bandwidth and thus more stations available in market areas. This made AM an even worse choice for music content than FM broadcast. Most AM content moved to news/talk because the content was better suited to the reduced audio bandwidth, didn't care about stereo audio, and importantly licenses were dirt cheap because most commercial stations had moved to FM.
When I see newsreels from the 1920s where someone is shown speaking into a microphone, their speaking style is noticeably different but also it usually sounds high pitched. Is this due to the recording equipment from those days or the broadcasting (replay) of the time?
Sometimes I wonder if people didn't just speak a little higher then. I've read many times in different places that people in Hollywood (especially women) were taught to lower their voices (pitch-wise) to sound "better". There are stories of actresses taking up smoking or just screaming into pillows. One of those actresses was Gene Tierney who was horrified when she heard her voice in her first movie and worked hard on changing it.
There's one thing I did not go into in my previous response - the microphones in use. I'm not as well-versed in microphone tech, especially the history of microphone tech, as I am in the history of radio transmission in general. A quick google indicates that part of the reason for the tinny sound in old newsreels may be the microphones in use. Carbon microphones, which were the first really viable way to convert sound into electricity, have poor bass response - they have a peak response around 2-3kHz. They're still in use on old-style phones, if you can find an old-style phone. This drives both the transmission band used for POTS I mentioned above (no sense transmitting a frequency you can't record), and possibly the tinny sound of old newsreels, pre-1930 or so.
Around 1930, the first condenser microphones started to come into wider use. They had a better high-band response, capturing up to 6 kHz. suggests, but does not state outright, that the newer technology probably had a better low-end response. About a slightly earlier innovation working with a carbon microphone, it says, "The resulting “Reisz marble block microphone” was fairly flat from 50 to 1k Hz, with a 10dB peak at 4 kHz, and was -15 dB at 10 kHz.".
I am somewhat confused by your description of FM/AM. In my youth, pop music was almost exclusively on the AM bands. (I'm in the US) Indeed, when small cheap transistor radios came out, they often would not even receive FM.
10dB is still a really huge peak - it's 10x the power output, so if a flat-power-frequency sound came out as 0.1W at 500 Hz, it would show up as 1W at 4kHz.
Nothing else I can find focuses on low-frequency response. A lower-frequency sound has a longer wavelenh to cause bigger physical movement that can be converted into electronic signals more easily. Moving higher is much harder than moving lower in the microphone response band, so all the documentation and development focuses on better high-band response, not better low-band. I suspect, but cannot prove, that better low band response comes as a freebie as you improve high-band response.
Granted, if you were a fan of classical music, you would usually have an expensive in home receiver for FM. But for us in our teens and 20s, it was AM that brought us Wolfman Jack playing Buddy Holly on our dinky little battery powered sets, in mono only to boot. Did the quality not matter (likely) or did pop music not rely on high frequency tones?
To how this affects the original question: I am most familiar with the Transatlantic Accent in the golden age of Hollywood, say 1930-1950. By this time, the Neumann condenser mic was in wide-spread use, with it's much better frequency response. Thus, a tinny carbon microphone should not have driven this speech pattern, unless it developed in the 1910s-1920s and just persisted throughout the next 40 years.