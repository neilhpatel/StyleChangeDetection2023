(This is a very US-centric response given the way OP phrased their question, but there are fascinating threads elsewhere in the world, such as the civil service exam system in China, that I hope others can address.).
Katzell, R. A., & Austin, J. T. (1992). From then to now: The development of industrial-organizational psychology in the United States. Journal of Applied Psychology, 77(6), 803-835.
Katzell and Austin (1992) identified four major non-psychology forces that emerged between Catell's early work and the outbreak of WWI that fueled massive growth in personnel selection practices:
What most people would consider modern selection practices for jobs originated in the late 19th century. We credit the early psychologist James McKeen Catell with originating the concept of a "mental test" in the 1890s and offering the conjecture that mental test scores could predict future performance in job and academic contexts. Hugo Münsterberg, who had vast interests in applied psychology of all kinds, advanced this line of thinking with his work Psychology and Industrial Efficiency (1913). This text offered the first complete thinking about selecting people for the work to which they are best suited, and likely to be successful, based on their abilities and attributes.
- Growing American mythologies around meritocracy and work ethic that fueled a desire to identify "deserving" candidates for jobs.
- The emergence of management as an intellectual discipline, driven in large part by Frederick Winslow Taylor's work on "scientific management" that was highly publicized to the general public.
- Basic advances in statistical concepts that made forecasting performance via statistical inference possible.
- Increasing acceptance of Darwinian evolutionary concepts, including the bastardized application of natural selection to personnel selection.
Being denied work opportunities long pre-dates modern technology. The problem is that your example assumes a limitless market for lumber (or any other product). The reality is that this job, and the goods/services it produces, exists as part of a broader market. Companies didn't hire endlessly because there were limits on what the market demanded, and so you they couldn't employ everyone who wanted a job (even if they could all do the job). For example, when economies are in a recession or depression and demand for products slumps, unemployment spikes despite the fact that people are still capable of doing jobs.
The outbreak of both World Wars was also massively important to advancing modern personnel selection. Both war efforts drew on the talents of applied psychologists to develop new assessments and solve practical problems of selecting, placing, and organizing huge numbers of people to create efficient and effective military and civilian forces. Critically, both wars also normalized selection by exposing recruits to these practices, which subsequently enabled those practices to easily spill out into the postwar public and private sectors with little resistance from applicants. For example, the first cognitive ability test used for widespread personnel selection was the Army Alpha (and Beta, the parallel version for illiterate recruits) developed by Robert Yerkes and the Committee on the Psychological Examination of Recruits. This is a terribly imperfect test in a great many respects, but it was the first systemic tool used to identify Army recruits who were suitable for officer training.
Selection has come a long way since the late 1940s, but immediate post-WWII selection practices would be recognizable to most people today. By that point, tools such as interviews, work samples, simulations, and tests/questionnaires were adopted by large businesses, such as AT&T, that eagerly hired many of the applied psychologists who worked on wartime selection problems, such as Donald MacKinnon (whose work on selecting spies for the nascent OSS/CIA is both fascinating and hilarious). These practices became benchmarks that other businesses rapidly adopted.
Presumably, before the invention of "job interviews", pretty much everyone who wanted to work someplace would be hired. The whole point of doing interviews is to reject candidates. If you're going to hire everybody, then you don't need a mechanism to reject anyone.
Wow That’s fascinating As a follow up, when did an interview turn into an application, resume, cover letter, phone interview, and 1-2 in-person interviews?
Well, resumes date back to the 15th century, although they were more similar to a cover letter at that point than a modern resume (i.e., a loose statement describing abilities, achievements, and suitability for an opportunity). Those pieces, along with letters of introduction that acted as "recommendations" or references of various types, pre-date other selection tools in Europe and the US. The kind of broader, formalized application process with a selection battery that you're describing emerged post-WWII, driven by expanding organizational bureaucracy, the proliferation of complex jobs, research advances in industrial/organizational psychology on selection best practices, and (eventually) IT advances that streamline or automate much of this process in various ways (not always helpful, especially on the applicant side).